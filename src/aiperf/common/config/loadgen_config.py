# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

from typing import Annotated

from pydantic import Field

from aiperf.common.config.base_config import BaseConfig
from aiperf.common.config.cli_parameter import CLIParameter
from aiperf.common.config.config_defaults import LoadGeneratorDefaults
from aiperf.common.config.groups import Groups
from aiperf.common.enums import RequestRateMode


class LoadGeneratorConfig(BaseConfig):
    """
    A configuration class for defining top-level load generator settings.
    """

    _CLI_GROUP = Groups.LOAD_GENERATOR

    # NEW AIPerf Option
    benchmark_duration: Annotated[
        float | None,
        Field(
            ge=1,
            description="The duration in seconds for benchmarking.",
        ),
        CLIParameter(
            name=("--benchmark-duration",),
            group=_CLI_GROUP,
        ),
    ] = LoadGeneratorDefaults.BENCHMARK_DURATION

    # NEW AIPerf Option
    benchmark_grace_period: Annotated[
        float,
        Field(
            ge=0,
            description="The grace period in seconds to wait for responses after benchmark duration ends. "
            "Only applies when --benchmark-duration is set. Responses received within this period "
            "are included in metrics.",
        ),
        CLIParameter(
            name=("--benchmark-grace-period",),
            group=_CLI_GROUP,
        ),
    ] = LoadGeneratorDefaults.BENCHMARK_GRACE_PERIOD

    # TODO: Potentially add a validator to ensure that the concurrency is not greater than the request count
    concurrency: Annotated[
        int | None,
        Field(
            ge=1,
            description="The concurrency value to benchmark.",
        ),
        CLIParameter(
            name=(
                "--concurrency",  # GenAI-Perf
            ),
            group=_CLI_GROUP,
        ),
    ] = LoadGeneratorDefaults.CONCURRENCY

    request_rate: Annotated[
        float | None,
        Field(
            gt=0,
            description="Sets the request rate for the load generated by AIPerf. Unit: requests/second",
        ),
        CLIParameter(
            name=(
                "--request-rate",  # GenAI-Perf
            ),
            group=_CLI_GROUP,
        ),
    ] = LoadGeneratorDefaults.REQUEST_RATE

    # NEW AIPerf Option
    request_rate_mode: Annotated[
        RequestRateMode,
        Field(
            description="Sets the request rate mode for the load generated by AIPerf. Valid values: constant, poisson.\n"
            "constant: Generate requests at a fixed rate.\n"
            "poisson: Generate requests using a poisson distribution."
        ),
        CLIParameter(
            name=("--request-rate-mode"),
            group=_CLI_GROUP,
            show_choices=False,
        ),
    ] = LoadGeneratorDefaults.REQUEST_RATE_MODE

    request_count: Annotated[
        int,
        Field(
            ge=1,
            description="The number of requests to use for measurement.",
        ),
        CLIParameter(
            name=(
                "--request-count",  # GenAI-Perf
                "--num-requests",  # GenAI-Perf
            ),
            group=_CLI_GROUP,
        ),
    ] = LoadGeneratorDefaults.REQUEST_COUNT

    warmup_request_count: Annotated[
        int,
        Field(
            ge=0,
            description="The number of warmup requests to send before benchmarking.",
        ),
        CLIParameter(
            name=(
                "--warmup-request-count",  # GenAI-Perf
                "--num-warmup-requests",  # GenAI-Perf
            ),
            group=_CLI_GROUP,
        ),
    ] = LoadGeneratorDefaults.WARMUP_REQUEST_COUNT

    # NEW AIPerf Option
    request_cancellation_rate: Annotated[
        float,
        Field(
            ge=0.0,
            le=100.0,
            description="The percentage of requests to cancel.",
        ),
        CLIParameter(
            name=("--request-cancellation-rate",),
            group=_CLI_GROUP,
        ),
    ] = LoadGeneratorDefaults.REQUEST_CANCELLATION_RATE

    # NEW AIPerf Option
    request_cancellation_delay: Annotated[
        float,
        Field(
            ge=0.0,
            description="The delay in seconds before cancelling requests. "
            "This is used when --request-cancellation-rate is greater than 0.",
        ),
        CLIParameter(
            name=("--request-cancellation-delay",),
            group=_CLI_GROUP,
        ),
    ] = LoadGeneratorDefaults.REQUEST_CANCELLATION_DELAY
